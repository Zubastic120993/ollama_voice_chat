
# Flask & AI configuration
OLLAMA_URL = "http://localhost:11434/v1"
OLLAMA_MODEL = "llama3-engineer"   # custom modelfile version
VOSK_MODEL_PATH = "models/en_full"

# App behavior
DEBUG_MODE = True
